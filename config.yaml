BASE_MODEL_NAME: distilbert-base-uncased
BATCH_SIZE: 16
COMPUTE_METRICS: true
DATASET_CONFIG_NAME: null
DATASET_NAME: imdb
DISTILL: true
DISTILL_ALPHA: 0.4
DISTILL_TEACHER: dfg
HF_TOKEN: hf_YOUR_TOKEN_HERE
LEARNING_RATE: 2.0e-05
LOG_LEVEL: error
METRICS:
- accuracy: {}
- f1:
    average: micro
- glue:
  - qqp
NUM_EPOCHS: 3
PUSH_TO_HUB: true
TASK: text-classification
WARMUP_STEPS: 500
WEIGHT_DECAY: 0.01
